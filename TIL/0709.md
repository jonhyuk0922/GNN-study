Title : Prediction with GNNs 
 
 - GNN Training Pipeline
Input Graph -> Graph Neural Network -> Node embeddings -> Prediction head -> predictions and labels -> Loss function & Evaluation metircs
위와 같은 학습 파이프라인을 따를 때, 우리는 GNN의 output(set of node embeddings)을 3가지 레벨(node, edge ,graph)의 task로 나타낼 수 있다.

- 아이디어는 다른 레벨의 task는 다른 prediction heads를 요청한다. @매핑에 대한 자료 있으면 좋을듯
1. node-level prediction : d-dim node embeddings 에서 k-way prediction을 얻고자 할 때 , 분류는 k개의 카테고리에 대한 값을 나타내고 회귀는 k개의 타겟값을 regress한다.
수식은 임베딩해서 나온 아웃풋 hv(L)에 W(H)를 곱해서 prediction head y_hat_v를 구한다. 다시말해 h에 W를 곱해서 k-dim y_hat을로 매핑시킩다.

2. Edge-level prediction : k-way prediction 이라고 가정. 두 가지 옵션이 있다. @ graph Attention 에 대한 추가 자료 있으면 좋을듯
- 1) Concatenation + Linear : graph attention에서 나온 concat 후 linear로 head를 구한 후 softmax/sigmoid 함수로 점수를 낸다. 우리가 concat 했기 때문에 linear 함수는 2d를 k-dimd으로 매핑해준다. 
- 2) Dot product : 1-way-prediction일 때만 사용 가능하며, 예를 들어 이진분류 나 연결유무를 확인할 떄 쓸 수 있다. 말 그래도 hu(L)과 hv(L)벡터를 내적해준다. 만약 k-way prediction에 사용하고 싶다면,
내적 중간에 W(1) ~W(k)를 넣어서 계산해준 후 마지막에 k개의 y hat을 concat 해준다. multi-head attention과 유사하며 이렇게 할 경우 W를 축소,확대,회전,변환이 가능해져서 학습가능한 상태가 된다.

3. Graph-level prediction : 노드별 임베딩 후 Head_graph()함수를 씌워서 그래프 임베딩값을 도출하는데 이 과정은 GNN에서 aggregation layer AGG() 와 비슷하다.
- 몇가지 옵션이 있는데, Global mean, max, sum pooling 이 있다. 그래프 크기를 비교할 때 사용된다. 하지만 노드 갯수나 구조는 알수없고 이럴 땐 sum이 낫다. 
- 다만 전체를 대상으로 하는 건 한계가 있다. 그래서 작은 그래프 일때만 작동하게 된다. 큰 그래프에 적용할 시에 정보 손실이 일어나는데,
예를 들어 {-1,-2,0,1,2} 그래프와 {-10,-20,0,10,20} 그래프에 sum을 씌우면 분명 다른 그래프임에도 같은 0값을 반환한다.

@ 이럴 때 사용하는 것이 "Hierarchical Global Pooling"이다. 게층을 나눠서 진행하는데 우리는 ReLU(Sum(-))을 통해 그룹화할것이다. 
그래프는 {-1,-2,0,1,2} , {-10,-20,0,10,20} 가 있을 때, 맨앞 두개와 그 이후로 나눠서 진행해준다.
우선 나눠서 sum을 해준 후 relu를 씌워주면 relu(sum({-1,-2})) = 0 , relu(sum({0,1,2})) = 3 / relu(sum({-10,-20})) = 0 , relu(sum({0,10,20})) = 30 이 나오고 나온 두개를 합쳐주면
0 + 3 = 3 != 30 = 0 +30 이므로 두 다른 그래프를 구분할 수 있게된다.

- DiffPool idea : Hierachically pool node embeddings 
커뮤니티 구조 , 즉 몇개의 노드들이 뭉쳐있는 듯한 것들이 모여읐는 그래프를 pooling한다고 치자, 앞에서 소개한 계층 풀링을 통해 각 군집별 슈퍼노드(그 군집을 풀링한 값)을 계산해주고, 또 슈퍼노드들의 군집을 풀링해서 그들의 슈퍼노드를 구한다.
마지막으로 한번더 풀링을 한 후 그 값을 통해 그래프 분류를 할 수 있다. 이 때 계산은 각 레벨 별로 병렬적으로 이뤄진다. GNN A 각 노드 임베딩 , GNN B 노드가 속한 군집 계산. 이때 GNN B에서 클러스터링 할당을 사용하여 GNN A에서 생성된 노드 임베딩 집계!

